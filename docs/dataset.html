<!DOCTYPE html>
<html>
<head>
    <title>Caltech Library's Digital Library Development Sandbox</title>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/css/site.css">
</head>
<body>
<header>
<a href="http://library.caltech.edu"><img src="/assets/liblogo.gif" alt="Caltech Library logo"></a>
</header>
<nav>
<ul>
<li><a href="/">Home</a></li>
<li><a href="../">README</a></li>
<li><a href="../license.html">LICENSE</a></li>
<li><a href="../install.html">INSTALL</a></li>
<li><a href="./">Documentation</a></li>
<li><a href="../how-to/">How To</a></li>
<li><a href="https://github.com/caltechlibrary/dataset">Github</a></li>
</ul>

</nav>

<section>
<h1>USAGE</h1>

<h2>dataset [OPTIONS] COMMAND_AND_PARAMETERS</h2>

<h2>SYNOPSIS</h2>

<p>dataset is a command line tool demonstrating dataset package for managing
JSON documents stored on disc. A dataset is organized around collections,
collections contain buckets holding specific JSON documents and related content.
In addition to the JSON documents dataset maintains metadata for management
of the documents, their attachments as well as a ability to generate select lists
based JSON document keys (aka JSON document names).</p>

<h2>COMMANDS</h2>

<p>Collection and JSON Documant related&ndash;</p>

<ul>
<li>init - initialize a new collection if none exists, requires a path to collection

<ul>
<li>once collection is created, set the environment variable DATASET
to collection name</li>
<li>if you&rsquo;re using S3 for storing your dataset prefix your path with &lsquo;s3://&rsquo;
&lsquo;dataset init s3://mybucket/mydataset-collections&rsquo;</li>
</ul></li>
<li>create - creates a new JSON document or replace an existing one in collection

<ul>
<li>requires JSON document name followed by JSON blob or JSON blob read from stdin</li>
</ul></li>
<li>read - displays a JSON document to stdout

<ul>
<li>requires JSON document name</li>
</ul></li>
<li>update - updates a JSON document in collection

<ul>
<li>requires JSON document name, followed by replacement JSON document name or
JSON document read from stdin</li>
<li>JSON document must already exist</li>
</ul></li>
<li>delete - removes a JSON document from collection

<ul>
<li>requires JSON document name</li>
</ul></li>
<li>join - brings the functionality of jsonjoin to the dataset command.

<ul>
<li>option update will only add unique key/values not in the existing stored document</li>
<li>option overwrite will overwrite all key/values in the existing document</li>
</ul></li>
<li>filter - takes a filter and returns an unordered list of keys that match filter expression

<ul>
<li>if filter expression not provided as a command line parameter then it is read from stdin</li>
</ul></li>
<li>keys - returns the keys to stdout, one key per line</li>
<li>haskey - returns true is key is in collection, false otherwise</li>
<li>path - given a document name return the full path to document</li>
<li>attach - attaches a non-JSON content to a JSON record

<ul>
<li>&ldquo;dataset attach k1 stats.xlsx&rdquo; would attach the stats.xlsx file to JSON document named k1</li>
<li>(stores content in a related tar file)</li>
</ul></li>
<li>attachments - lists any attached content for JSON document

<ul>
<li>&ldquo;dataset attachments k1&rdquo; would list all the attachments for k1</li>
</ul></li>
<li>attached - returns attachments for a JSON document

<ul>
<li>&ldquo;dataset attached k1&rdquo; would write out all the attached files for k1</li>
<li>&ldquo;dataset attached k1 stats.xlsx&rdquo; would write out only the stats.xlsx file attached to k1</li>
</ul></li>
<li>detach - remove attachments to a JSON document

<ul>
<li>&ldquo;dataset detach k1 stats.xlsx&rdquo; would rewrite the attachments tar file without including stats.xlsx</li>
<li>&ldquo;dataset detach k1&rdquo; would remove ALL attachments to k1</li>
</ul></li>
<li>import - import a CSV file&rsquo;s rows as JSON documents

<ul>
<li>&ldquo;dataset import mydata.csv 1&rdquo; would import the CSV file mydata.csv using column one&rsquo;s value as key</li>
</ul></li>
<li>export - export a CSV file based on filtered results of collection records rendering dotpaths associated with column names

<ul>
<li>&ldquo;dataset export titles.csv &lsquo;true&rsquo; &lsquo;._id,.title,.pubDate&rsquo; &lsquo;id,title,publication date&rsquo;&rdquo;
this would export all the ids, titles and publication dates as a CSV fiile named titles.csv</li>
</ul></li>
<li>extract - will return a unique list of unique values based on the associated dot path described in the JSON docs

<ul>
<li>&ldquo;dataset extract true .authors[:].orcid&rdquo; would extract a list of authors&rsquo; orcid ids in collection</li>
</ul></li>
</ul>

<h2>OPTIONS</h2>

<pre><code>-c  sets the collection to be used
-collection sets the collection to be used
-h  display help
-help   display help
-i  input filename
-input  input filename
-l  display license
-license    display license
-no-newline suppress a trailing newline on output
-o  output filename
-output output filename
-quiet  suppress error and status output
-skip-header-row    skip the header row (use as property names)
-uuid   generate a UUID for a new JSON document name
-v  display version
-verbose    output rows processed on importing from CSV
-version    display version
</code></pre>

<h2>EXAMPLES</h2>

<p>This is an example of creating a dataset called testdata/friends, saving
a record called &ldquo;littlefreda.json&rdquo; and reading it back.</p>

<pre><code class="language-shell">   dataset init testdata/friends
   export DATASET=testdata/friends
   dataset create littlefreda '{&quot;name&quot;:&quot;Freda&quot;,&quot;email&quot;:&quot;little.freda@inverness.example.org&quot;}'
   for KY in $(dataset keys); do
      echo &quot;Path: $(dataset path $KY) 
      echo &quot;Doc: $(dataset read $KY)
   done
</code></pre>

<p>Now check to see if the key, littlefreda, is in the collection</p>

<pre><code class="language-shell">   dataset haskey littlefreda
</code></pre>

<p>You can also read your JSON formatted data from a file or standard input.
In this example we are creating a mojosam record and reading back the contents
of testdata/friends</p>

<pre><code class="language-shell">   dataset -i mojosam.json create mojosam
   for KY in $(dataset keys); do
      echo &quot;Path: $(dataset path $KY) 
      echo &quot;Doc: $(dataset read $KY)
   done
</code></pre>

<p>Or similarly using a Unix pipe to create a &ldquo;capt-jack&rdquo; JSON record.</p>

<pre><code class="language-shell">   cat capt-jack.json | dataset create capt-jack
   for KY in $(dataset keys); do
      echo &quot;Path: $(dataset path $KY) 
      echo &quot;Doc: $(dataset read $KY)
   done
</code></pre>

<p>Adding high-capt-jack.txt as an attachment to &ldquo;capt-jack&rdquo;</p>

<pre><code class="language-shell">   echo &quot;Hi Capt. Jack, Hello World!&quot; &gt; high-capt-jack.txt
   dataset attach capt-jack high-capt-jack.txt
</code></pre>

<p>List attachments for &ldquo;capt-jack&rdquo;</p>

<pre><code class="language-shell">   dataset attachments capt-jack
</code></pre>

<p>Get the attachments for &ldquo;capt-jack&rdquo; (this will untar in your current directory)</p>

<pre><code class="language-shell">   dataset attached capt-jack
</code></pre>

<p>Remove high-capt-jack.txt from &ldquo;capt-jack&rdquo;</p>

<pre><code class="language-shell">    dataset detach capt-jack high-capt-jack.txt
</code></pre>

<p>Remove all attachments from &ldquo;capt-jack&rdquo;</p>

<pre><code class="language-shell">   dataset detach capt-jack
</code></pre>

<p>Filter can be used to return only the record keys that return true for a given
expression. Here&rsquo;s is a simple case for match records where name is equal to
&ldquo;Mojo Sam&rdquo;.</p>

<pre><code class="language-shell">   dataset filter '(eq .name &quot;Mojo Sam&quot;)'
</code></pre>

<p>If you are using a complex filter it can read a file in and apply it as a filter.</p>

<pre><code class="language-shell">   dataset filter &lt; myfilter.txt
</code></pre>

<p>Import can take a CSV file and store each row as a JSON document in dataset. In
this example we&rsquo;re generating a UUID for the key name of each row</p>

<pre><code class="language-shell">   dataset -uuid import my-data.csv
</code></pre>

<p>You can create a CSV export by providing the dot paths for each column and
then givening columns a name.</p>

<pre><code class="language-shell">   dataset export titles.csv true '.id,.title,.pubDate' 'id,title,publication date'
</code></pre>

<p>If you wanted to restrict to a subset (e.g. publication in year 2016)</p>

<pre><code class="language-shell">   dataset export titles2016.csv '(eq 2016 (year .pubDate))' \
           '.id,.title,.pubDate' 'id,title,publication date'
</code></pre>

<p>If wanted to extract a unqie list of all ORCIDs from a collection</p>

<pre><code class="language-shell">   dataset extract true .authors[:].orcid
</code></pre>

<p>If you wanted to extract a list of ORCIDs from publications in 2016.</p>

<pre><code class="language-shell">   dataset extract '(eq 2016 (year .pubDate))' .authors[:].orcid
</code></pre>

<p>You can augement JSON key/value pairs for a JSON document in your collection
using the join operation. This works similar to the datatools cli called jsonjoin.</p>

<p>Let&rsquo;s assume you have a record in your collection with a key &lsquo;jane.doe&rsquo;. It has
three fields - name, email, age.</p>

<pre><code class="language-json">    {&quot;name&quot;:&quot;Doe, Jane&quot;, &quot;email&quot;: &quot;jd@example.org&quot;, &quot;age&quot;: 42}
</code></pre>

<p>You also have an external JSON document called profile.json. It looks like</p>

<pre><code class="language-json">    {&quot;name&quot;: &quot;Doe, Jane&quot;, &quot;email&quot;: &quot;jane.doe@example.edu&quot;, &quot;bio&quot;: &quot;world renowned geophysist&quot;}
</code></pre>

<p>You can merge the unique fields in profile.json with your existing jane.doe record</p>

<pre><code class="language-shell">    dataset join update jane.doe profile.json
</code></pre>

<p>The result would look like</p>

<pre><code class="language-json">    {&quot;name&quot;:&quot;Doe, Jane&quot;, &quot;email&quot;: &quot;jd@example.org&quot;, &quot;age&quot;: 42, &quot;bio&quot;: &quot;renowned geophysist&quot;}
</code></pre>

<p>If you wanted to overwrite the common fields you would use &lsquo;join overwrite&rsquo;</p>

<pre><code class="language-shell">    dataset join overwrite jane.doe profile.json
</code></pre>

<p>Which would result in a record like</p>

<pre><code class="language-json">    {&quot;name&quot;:&quot;Doe, Jane&quot;, &quot;email&quot;: &quot;jane.doe@example.edu&quot;, &quot;age&quot;: 42, &quot;bio&quot;: &quot;renowned geophysist&quot;}
</code></pre>

<p>dataset v0.0.3-rc8</p>

</section>

<footer>
<span><h1><A href="http://caltech.edu">Caltech</a></h1></span>
<span>&copy; 2017 <a href="https://www.library.caltech.edu/copyright">Caltech library</a></span>
<address>1200 E California Blvd, Mail Code 1-32, Pasadena, CA 91125-3200</address> 
<span>Phone: <a href="tel:+1-626-395-3405">(626)395-3405</a></span>
<span><a href="mailto:library@caltech.edu">Email Us</a></span>
<a class="cl-hide" href="sitemap.xml">Site Map</a>
</footer>
</body>
</html>
